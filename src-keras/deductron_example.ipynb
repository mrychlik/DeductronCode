{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the deductron layer\n",
    "\n",
    "This notebook implements one of the examples from the Keras documentation for sequence-to-sequence learning using RNNs. The task is to solve addition problems, formulated as strings. For example, the network should be able to take the string `341+78 ` and return the sum `419`.\n",
    "\n",
    "This is accomplished using an encoding layer and a decoding layer. In the documentation example, both the encoder and the decoder are LSTMs. In this notebook, we generate some training data and train networks using both LSTMs and deductron layers.\n",
    "\n",
    "The code for this example is taken from https://keras.io/examples/nlp/addition_rnn/ and lightly modified to fit our use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import deductron\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True        # Reverse the order of the input strings -- this seems to improve learning\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# Although a sigmoid is a natural choice for an activation with values in (0, 1), a ReLU\n",
    "# constrained to produce output in [0, 1] has much better performance.\n",
    "clipped_relu = lambda x: keras.activations.relu(x, max_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate addition problems for training\n",
    "\n",
    "class CharacterTable:\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = \"0123456789+ \"\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(\n",
    "        \"\".join(\n",
    "            np.random.choice(list(\"0123456789\"))\n",
    "            for i in range(np.random.randint(1, DIGITS + 1))\n",
    "        )\n",
    "    )\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = \"{}+{}\".format(a, b)\n",
    "    query = q + \" \" * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the training and validation data\n",
    "\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference example: LSTM encoder/decoder\n",
    "\n",
    "The purpose of the next few sections is to compare the LSTM solution with a pure deductron solution as well as mixed LSTM-deductron solutions.\n",
    "\n",
    "The reference approach uses two layers, thinking of the first as an encoder and the second as a decoder. The first layer extracts features from the input and produces an internal representation of the problem. The final output of this \"encoder\" layer is then repeated to form a constant sequence and passed to the \"decoder\" layer as its input.\n",
    "\n",
    "Following the existing example, we begin by building a model in which each of the encoder and decoder is a single LSTM layer with 128 hidden units. Further examples will replace each of these layers in turn with a deductron layer (also with 128 units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "# Replacing the encoder with a deductron layer seems to hurt accuracy.\n",
    "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last output of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# We'll use a single layer for the decoder -- adding more layers doesn't seem to improve results\n",
    "model.add(layers.LSTM(128, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to train the model. We will train all of the models for 12 epochs (more would be better, but the training is a little time consuming). After each epoch we visualize 10 samples from the validation set so that we can see the sort of output we are getting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 27s 608us/step - loss: 1.7634 - accuracy: 0.3535 - val_loss: 1.6066 - val_accuracy: 0.3937\n",
      "Q 422+25  T 447  ☒ 358 \n",
      "Q 285+47  T 332  ☒ 587 \n",
      "Q 69+535  T 604  ☒ 622 \n",
      "Q 17+475  T 492  ☒ 587 \n",
      "Q 198+98  T 296  ☒ 992 \n",
      "Q 185+992 T 1177 ☒ 1247\n",
      "Q 360+83  T 443  ☒ 732 \n",
      "Q 37+308  T 345  ☒ 387 \n",
      "Q 26+472  T 498  ☒ 387 \n",
      "Q 22+196  T 218  ☒ 227 \n",
      "\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 23s 511us/step - loss: 1.3473 - accuracy: 0.4950 - val_loss: 1.1510 - val_accuracy: 0.5706\n",
      "Q 88+936  T 1024 ☒ 1010\n",
      "Q 274+67  T 341  ☒ 346 \n",
      "Q 613+16  T 629  ☒ 634 \n",
      "Q 871+2   T 873  ☒ 881 \n",
      "Q 243+472 T 715  ☒ 740 \n",
      "Q 508+6   T 514  ☒ 510 \n",
      "Q 616+5   T 621  ☒ 614 \n",
      "Q 583+94  T 677  ☒ 661 \n",
      "Q 58+323  T 381  ☒ 396 \n",
      "Q 586+14  T 600  ☒ 510 \n",
      "\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 24s 532us/step - loss: 1.0277 - accuracy: 0.6198 - val_loss: 0.9338 - val_accuracy: 0.6594\n",
      "Q 702+438 T 1140 ☒ 1153\n",
      "Q 749+31  T 780  ☒ 781 \n",
      "Q 30+89   T 119  ☒ 121 \n",
      "Q 117+4   T 121  ☒ 118 \n",
      "Q 70+747  T 817  ☒ 818 \n",
      "Q 306+331 T 637  ☒ 638 \n",
      "Q 81+29   T 110  ☒ 111 \n",
      "Q 158+285 T 443  ☒ 434 \n",
      "Q 98+88   T 186  ☒ 181 \n",
      "Q 25+56   T 81   ☒ 68  \n",
      "\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 24s 526us/step - loss: 0.8602 - accuracy: 0.6851 - val_loss: 0.7983 - val_accuracy: 0.7103\n",
      "Q 3+843   T 846  ☒ 843 \n",
      "Q 968+8   T 976  ☒ 973 \n",
      "Q 39+52   T 91   ☒ 90  \n",
      "Q 49+285  T 334  ☒ 333 \n",
      "Q 792+7   T 799  ☒ 790 \n",
      "Q 990+730 T 1720 ☒ 1620\n",
      "Q 163+7   T 170  ☒ 161 \n",
      "Q 31+25   T 56   ☒ 53  \n",
      "Q 33+672  T 705  ☒ 703 \n",
      "Q 671+449 T 1120 ☒ 1111\n",
      "\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 567us/step - loss: 0.7494 - accuracy: 0.7280 - val_loss: 0.7049 - val_accuracy: 0.7434\n",
      "Q 633+24  T 657  ☒ 665 \n",
      "Q 926+9   T 935  ☑ 935 \n",
      "Q 609+771 T 1380 ☒ 1382\n",
      "Q 9+110   T 119  ☑ 119 \n",
      "Q 85+581  T 666  ☒ 660 \n",
      "Q 763+0   T 763  ☑ 763 \n",
      "Q 860+76  T 936  ☒ 930 \n",
      "Q 5+790   T 795  ☒ 799 \n",
      "Q 198+622 T 820  ☒ 810 \n",
      "Q 53+838  T 891  ☒ 895 \n",
      "\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 614us/step - loss: 0.6595 - accuracy: 0.7625 - val_loss: 0.6142 - val_accuracy: 0.7763\n",
      "Q 131+714 T 845  ☒ 841 \n",
      "Q 551+55  T 606  ☒ 605 \n",
      "Q 179+31  T 210  ☒ 211 \n",
      "Q 9+83    T 92   ☒ 91  \n",
      "Q 873+774 T 1647 ☒ 1645\n",
      "Q 704+521 T 1225 ☒ 1234\n",
      "Q 837+5   T 842  ☑ 842 \n",
      "Q 639+743 T 1382 ☒ 1389\n",
      "Q 623+79  T 702  ☒ 701 \n",
      "Q 454+33  T 487  ☒ 486 \n",
      "\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 577us/step - loss: 0.4561 - accuracy: 0.8387 - val_loss: 0.3068 - val_accuracy: 0.9067\n",
      "Q 245+72  T 317  ☑ 317 \n",
      "Q 645+9   T 654  ☑ 654 \n",
      "Q 26+42   T 68   ☑ 68  \n",
      "Q 64+530  T 594  ☑ 594 \n",
      "Q 417+9   T 426  ☒ 425 \n",
      "Q 416+782 T 1198 ☑ 1198\n",
      "Q 461+7   T 468  ☑ 468 \n",
      "Q 84+594  T 678  ☑ 678 \n",
      "Q 154+476 T 630  ☑ 630 \n",
      "Q 0+534   T 534  ☑ 534 \n",
      "\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 29s 643us/step - loss: 0.2302 - accuracy: 0.9378 - val_loss: 0.1778 - val_accuracy: 0.9535\n",
      "Q 679+70  T 749  ☑ 749 \n",
      "Q 2+538   T 540  ☑ 540 \n",
      "Q 669+758 T 1427 ☑ 1427\n",
      "Q 405+55  T 460  ☑ 460 \n",
      "Q 116+584 T 700  ☑ 700 \n",
      "Q 379+29  T 408  ☑ 408 \n",
      "Q 90+733  T 823  ☑ 823 \n",
      "Q 370+398 T 768  ☑ 768 \n",
      "Q 618+4   T 622  ☑ 622 \n",
      "Q 0+31    T 31   ☒ 33  \n",
      "\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 30s 661us/step - loss: 0.1356 - accuracy: 0.9687 - val_loss: 0.0973 - val_accuracy: 0.9803\n",
      "Q 33+904  T 937  ☑ 937 \n",
      "Q 335+867 T 1202 ☑ 1202\n",
      "Q 492+807 T 1299 ☑ 1299\n",
      "Q 98+808  T 906  ☑ 906 \n",
      "Q 269+976 T 1245 ☑ 1245\n",
      "Q 454+262 T 716  ☑ 716 \n",
      "Q 976+22  T 998  ☑ 998 \n",
      "Q 613+4   T 617  ☑ 617 \n",
      "Q 533+271 T 804  ☑ 804 \n",
      "Q 815+27  T 842  ☑ 842 \n",
      "\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 27s 590us/step - loss: 0.0867 - accuracy: 0.9803 - val_loss: 0.1264 - val_accuracy: 0.9571\n",
      "Q 969+57  T 1026 ☑ 1026\n",
      "Q 92+590  T 682  ☑ 682 \n",
      "Q 100+31  T 131  ☒ 141 \n",
      "Q 357+33  T 390  ☑ 390 \n",
      "Q 14+474  T 488  ☑ 488 \n",
      "Q 269+332 T 601  ☒ 501 \n",
      "Q 573+42  T 615  ☑ 615 \n",
      "Q 527+33  T 560  ☑ 560 \n",
      "Q 47+45   T 92   ☑ 92  \n",
      "Q 249+5   T 254  ☑ 254 \n",
      "\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 26s 578us/step - loss: 0.0584 - accuracy: 0.9869 - val_loss: 0.0452 - val_accuracy: 0.9901\n",
      "Q 7+870   T 877  ☒ 876 \n",
      "Q 8+581   T 589  ☑ 589 \n",
      "Q 870+745 T 1615 ☑ 1615\n",
      "Q 735+832 T 1567 ☑ 1567\n",
      "Q 396+82  T 478  ☑ 478 \n",
      "Q 811+61  T 872  ☑ 872 \n",
      "Q 6+95    T 101  ☑ 101 \n",
      "Q 545+152 T 697  ☑ 697 \n",
      "Q 616+5   T 621  ☑ 621 \n",
      "Q 993+656 T 1649 ☑ 1649\n",
      "\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 615us/step - loss: 0.0589 - accuracy: 0.9842 - val_loss: 0.2094 - val_accuracy: 0.9308\n",
      "Q 11+656  T 667  ☑ 667 \n",
      "Q 24+917  T 941  ☑ 941 \n",
      "Q 59+767  T 826  ☑ 826 \n",
      "Q 569+964 T 1533 ☒ 1523\n",
      "Q 1+36    T 37   ☒ 47  \n",
      "Q 772+80  T 852  ☒ 853 \n",
      "Q 40+205  T 245  ☒ 246 \n",
      "Q 436+79  T 515  ☑ 515 \n",
      "Q 76+84   T 160  ☑ 160 \n",
      "Q 41+83   T 124  ☑ 124 \n"
     ]
    }
   ],
   "source": [
    "epochs = 12\n",
    "batch_size = 32\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for epoch in range(0, epochs):\n",
    "    print()\n",
    "    print(\"Iteration\", epoch)\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(\"☑ \" + guess)\n",
    "        else:\n",
    "            print(\"☒ \" + guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, after 12 epochs, the above network should reach about 98-99% accuracy, with most visualized problems solved correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A pure deductron implementation\n",
    "\n",
    "Our first change is to replace both the encoder and decoder LSTM layers with deductron layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "deductron_1 (Deductron)      (None, 128)               19840     \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "deductron_2 (Deductron)      (None, 4, 128)            49536     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 70,924\n",
      "Trainable params: 70,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(deductron.Deductron(128, activation = clipped_relu, input_shape=(MAXLEN, len(chars))))\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "model.add(deductron.Deductron(128, activation = clipped_relu, return_sequences=True))\n",
    "\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 38s 846us/step - loss: 1.8258 - accuracy: 0.3457 - val_loss: 1.7251 - val_accuracy: 0.3729\n",
      "Q 875+299 T 1174 ☒ 1466\n",
      "Q 870+71  T 941  ☒ 189 \n",
      "Q 984+32  T 1016 ☒ 122 \n",
      "Q 85+886  T 971  ☒ 144 \n",
      "Q 868+53  T 921  ☒ 133 \n",
      "Q 11+56   T 67   ☒ 16  \n",
      "Q 70+887  T 957  ☒ 164 \n",
      "Q 609+771 T 1380 ☒ 1144\n",
      "Q 900+77  T 977  ☒ 176 \n",
      "Q 8+638   T 646  ☒ 13  \n",
      "\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 37s 817us/step - loss: 1.6641 - accuracy: 0.3972 - val_loss: 1.6397 - val_accuracy: 0.4004\n",
      "Q 14+48   T 62   ☒ 428 \n",
      "Q 0+525   T 525  ☒ 556 \n",
      "Q 81+29   T 110  ☒ 120 \n",
      "Q 748+943 T 1691 ☒ 1222\n",
      "Q 332+829 T 1161 ☒ 1266\n",
      "Q 39+61   T 100  ☒ 120 \n",
      "Q 781+995 T 1776 ☒ 1666\n",
      "Q 44+3    T 47   ☑ 47  \n",
      "Q 926+9   T 935  ☒ 900 \n",
      "Q 637+56  T 693  ☒ 722 \n",
      "\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 36s 795us/step - loss: 1.5765 - accuracy: 0.4205 - val_loss: 1.5436 - val_accuracy: 0.4284\n",
      "Q 228+28  T 256  ☒ 300 \n",
      "Q 63+95   T 158  ☒ 999 \n",
      "Q 989+922 T 1911 ☒ 1110\n",
      "Q 87+796  T 883  ☒ 865 \n",
      "Q 68+999  T 1067 ☒ 106 \n",
      "Q 749+31  T 780  ☒ 322 \n",
      "Q 84+376  T 460  ☒ 711 \n",
      "Q 23+939  T 962  ☒ 122 \n",
      "Q 98+88   T 186  ☒ 977 \n",
      "Q 84+951  T 1035 ☒ 1033\n",
      "\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 37s 826us/step - loss: 1.5094 - accuracy: 0.4446 - val_loss: 1.4666 - val_accuracy: 0.4624\n",
      "Q 413+50  T 463  ☒ 555 \n",
      "Q 842+30  T 872  ☒ 862 \n",
      "Q 640+439 T 1079 ☒ 103 \n",
      "Q 185+52  T 237  ☒ 233 \n",
      "Q 9+186   T 195  ☒ 177 \n",
      "Q 58+22   T 80   ☒ 233 \n",
      "Q 994+6   T 1000 ☒ 905 \n",
      "Q 612+264 T 876  ☒ 808 \n",
      "Q 919+39  T 958  ☒ 900 \n",
      "Q 837+5   T 842  ☒ 133 \n",
      "\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 36s 805us/step - loss: 1.4508 - accuracy: 0.4656 - val_loss: 1.4105 - val_accuracy: 0.4790\n",
      "Q 80+742  T 822  ☒ 844 \n",
      "Q 69+125  T 194  ☒ 225 \n",
      "Q 44+622  T 666  ☑ 666 \n",
      "Q 486+85  T 571  ☒ 644 \n",
      "Q 570+21  T 591  ☒ 671 \n",
      "Q 103+19  T 122  ☒ 130 \n",
      "Q 621+337 T 958  ☒ 904 \n",
      "Q 328+612 T 940  ☒ 400 \n",
      "Q 335+6   T 341  ☒ 30  \n",
      "Q 36+415  T 451  ☒ 499 \n",
      "\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 37s 820us/step - loss: 1.3980 - accuracy: 0.4848 - val_loss: 1.3742 - val_accuracy: 0.4882\n",
      "Q 981+184 T 1165 ☒ 1959\n",
      "Q 59+175  T 234  ☒ 266 \n",
      "Q 541+1   T 542  ☒ 555 \n",
      "Q 2+920   T 922  ☑ 922 \n",
      "Q 271+330 T 601  ☒ 903 \n",
      "Q 304+3   T 307  ☒ 33  \n",
      "Q 22+778  T 800  ☒ 899 \n",
      "Q 86+31   T 117  ☒ 199 \n",
      "Q 420+6   T 426  ☒ 622 \n",
      "Q 744+709 T 1453 ☒ 1448\n",
      "\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 35s 782us/step - loss: 1.3611 - accuracy: 0.4972 - val_loss: 1.3544 - val_accuracy: 0.4936\n",
      "Q 958+656 T 1614 ☒ 1151\n",
      "Q 488+702 T 1190 ☒ 1228\n",
      "Q 96+79   T 175  ☒ 105 \n",
      "Q 416+424 T 840  ☒ 766 \n",
      "Q 462+824 T 1286 ☒ 1066\n",
      "Q 273+177 T 450  ☒ 444 \n",
      "Q 621+69  T 690  ☒ 771 \n",
      "Q 76+774  T 850  ☒ 841 \n",
      "Q 73+256  T 329  ☒ 789 \n",
      "Q 294+425 T 719  ☒ 700 \n",
      "\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 32s 714us/step - loss: 1.3151 - accuracy: 0.5147 - val_loss: 1.3020 - val_accuracy: 0.5149\n",
      "Q 218+12  T 230  ☑ 230 \n",
      "Q 830+8   T 838  ☒ 831 \n",
      "Q 4+230   T 234  ☒ 333 \n",
      "Q 42+288  T 330  ☒ 400 \n",
      "Q 79+698  T 777  ☑ 777 \n",
      "Q 25+12   T 37   ☒ 13  \n",
      "Q 662+933 T 1595 ☒ 1555\n",
      "Q 60+858  T 918  ☒ 804 \n",
      "Q 736+599 T 1335 ☒ 1444\n",
      "Q 132+633 T 765  ☒ 695 \n",
      "\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 32s 720us/step - loss: 1.2671 - accuracy: 0.5336 - val_loss: 1.2643 - val_accuracy: 0.5315\n",
      "Q 561+387 T 948  ☒ 109 \n",
      "Q 197+77  T 274  ☒ 266 \n",
      "Q 953+493 T 1446 ☒ 1388\n",
      "Q 86+31   T 117  ☒ 19  \n",
      "Q 226+512 T 738  ☒ 577 \n",
      "Q 558+53  T 611  ☒ 630 \n",
      "Q 495+678 T 1173 ☒ 1344\n",
      "Q 82+762  T 844  ☒ 808 \n",
      "Q 200+25  T 225  ☒ 250 \n",
      "Q 374+94  T 468  ☒ 432 \n",
      "\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 33s 728us/step - loss: 1.2179 - accuracy: 0.5523 - val_loss: 1.2128 - val_accuracy: 0.5462\n",
      "Q 329+87  T 416  ☒ 366 \n",
      "Q 42+117  T 159  ☒ 139 \n",
      "Q 775+48  T 823  ☒ 731 \n",
      "Q 624+622 T 1246 ☒ 906 \n",
      "Q 471+829 T 1300 ☒ 1100\n",
      "Q 777+7   T 784  ☒ 744 \n",
      "Q 2+86    T 88   ☑ 88  \n",
      "Q 372+3   T 375  ☒ 339 \n",
      "Q 15+136  T 151  ☒ 241 \n",
      "Q 201+5   T 206  ☒ 251 \n",
      "\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 42s 931us/step - loss: 1.1691 - accuracy: 0.5706 - val_loss: 1.1780 - val_accuracy: 0.5627\n",
      "Q 5+404   T 409  ☒ 445 \n",
      "Q 12+547  T 559  ☒ 599 \n",
      "Q 7+840   T 847  ☒ 841 \n",
      "Q 37+802  T 839  ☒ 831 \n",
      "Q 589+981 T 1570 ☒ 1779\n",
      "Q 26+173  T 199  ☒ 299 \n",
      "Q 887+0   T 887  ☒ 955 \n",
      "Q 75+155  T 230  ☒ 120 \n",
      "Q 511+615 T 1126 ☒ 1222\n",
      "Q 9+209   T 218  ☒ 299 \n",
      "\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 41s 920us/step - loss: 1.1302 - accuracy: 0.5834 - val_loss: 1.1307 - val_accuracy: 0.5771\n",
      "Q 40+334  T 374  ☒ 447 \n",
      "Q 98+649  T 747  ☒ 757 \n",
      "Q 40+52   T 92   ☒ 50  \n",
      "Q 7+915   T 922  ☒ 967 \n",
      "Q 669+758 T 1427 ☒ 1544\n",
      "Q 83+747  T 830  ☒ 811 \n",
      "Q 830+426 T 1256 ☒ 1124\n",
      "Q 202+8   T 210  ☒ 100 \n",
      "Q 267+6   T 273  ☒ 233 \n",
      "Q 251+177 T 428  ☒ 888 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print()\n",
    "    print(\"Iteration\", epoch)\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(\"☑ \" + guess)\n",
    "        else:\n",
    "            print(\"☒ \" + guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pure deductron network does improve accuracy with training, but learns much more slowly, reaching only around 58-60% accuracy after 12 epohcs. Visual inspection of the output shows many repeated digits and similar apparent patterns, possibly pointing to insufficient feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "deductron_3 (Deductron)      (None, 4, 128)            49536     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 123,276\n",
      "Trainable params: 123,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM encoder, deductron decoder\n",
    "model = keras.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "\n",
    "model.add(deductron.Deductron(128, activation = clipped_relu, return_sequences=True))\n",
    "\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 33s 733us/step - loss: 1.8104 - accuracy: 0.3410 - val_loss: 1.6040 - val_accuracy: 0.4069\n",
      "Q 3+874   T 877  ☒ 998 \n",
      "Q 535+674 T 1209 ☒ 1064\n",
      "Q 4+204   T 208  ☒ 444 \n",
      "Q 85+692  T 777  ☒ 905 \n",
      "Q 45+25   T 70   ☒ 14  \n",
      "Q 857+30  T 887  ☒ 995 \n",
      "Q 85+996  T 1081 ☒ 1005\n",
      "Q 674+69  T 743  ☒ 765 \n",
      "Q 95+72   T 167  ☒ 100 \n",
      "Q 23+54   T 77   ☒ 12  \n",
      "\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 619us/step - loss: 1.4378 - accuracy: 0.4794 - val_loss: 1.3240 - val_accuracy: 0.5109\n",
      "Q 21+275  T 296  ☒ 255 \n",
      "Q 280+802 T 1082 ☒ 100 \n",
      "Q 663+840 T 1503 ☒ 1555\n",
      "Q 360+39  T 399  ☒ 395 \n",
      "Q 846+14  T 860  ☒ 855 \n",
      "Q 366+903 T 1269 ☒ 1225\n",
      "Q 0+170   T 170  ☒ 110 \n",
      "Q 666+348 T 1014 ☒ 900 \n",
      "Q 45+36   T 81   ☒ 75  \n",
      "Q 412+722 T 1134 ☒ 1155\n",
      "\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 28s 632us/step - loss: 1.2222 - accuracy: 0.5565 - val_loss: 1.1154 - val_accuracy: 0.5948\n",
      "Q 682+66  T 748  ☒ 746 \n",
      "Q 19+63   T 82   ☒ 78  \n",
      "Q 843+24  T 867  ☒ 866 \n",
      "Q 850+68  T 918  ☒ 926 \n",
      "Q 0+535   T 535  ☒ 546 \n",
      "Q 51+86   T 137  ☒ 141 \n",
      "Q 33+16   T 49   ☒ 48  \n",
      "Q 502+379 T 881  ☒ 866 \n",
      "Q 508+979 T 1487 ☒ 1400\n",
      "Q 7+520   T 527  ☒ 513 \n",
      "\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 31s 696us/step - loss: 1.0248 - accuracy: 0.6280 - val_loss: 0.9538 - val_accuracy: 0.6569\n",
      "Q 899+409 T 1308 ☒ 1299\n",
      "Q 481+60  T 541  ☒ 543 \n",
      "Q 417+393 T 810  ☒ 803 \n",
      "Q 660+618 T 1278 ☑ 1278\n",
      "Q 830+8   T 838  ☒ 833 \n",
      "Q 643+68  T 711  ☑ 711 \n",
      "Q 13+161  T 174  ☒ 179 \n",
      "Q 961+995 T 1956 ☒ 1761\n",
      "Q 735+7   T 742  ☒ 743 \n",
      "Q 86+854  T 940  ☒ 931 \n",
      "\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 31s 683us/step - loss: 0.9010 - accuracy: 0.6785 - val_loss: 0.8591 - val_accuracy: 0.6906\n",
      "Q 17+591  T 608  ☒ 609 \n",
      "Q 906+65  T 971  ☒ 976 \n",
      "Q 58+49   T 107  ☒ 104 \n",
      "Q 288+21  T 309  ☒ 314 \n",
      "Q 796+0   T 796  ☒ 799 \n",
      "Q 882+101 T 983  ☒ 999 \n",
      "Q 52+667  T 719  ☒ 721 \n",
      "Q 952+510 T 1462 ☒ 1467\n",
      "Q 6+677   T 683  ☒ 674 \n",
      "Q 47+194  T 241  ☒ 234 \n",
      "\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 31s 684us/step - loss: 0.8089 - accuracy: 0.7093 - val_loss: 0.7365 - val_accuracy: 0.7153\n",
      "Q 704+21  T 725  ☑ 725 \n",
      "Q 604+388 T 992  ☒ 987 \n",
      "Q 526+166 T 692  ☒ 685 \n",
      "Q 91+738  T 829  ☒ 817 \n",
      "Q 129+82  T 211  ☒ 201 \n",
      "Q 58+138  T 196  ☒ 295 \n",
      "Q 558+40  T 598  ☑ 598 \n",
      "Q 396+24  T 420  ☒ 421 \n",
      "Q 966+1   T 967  ☒ 966 \n",
      "Q 35+177  T 212  ☒ 217 \n",
      "\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 31s 688us/step - loss: 0.5127 - accuracy: 0.8362 - val_loss: 0.3766 - val_accuracy: 0.9150\n",
      "Q 52+382  T 434  ☑ 434 \n",
      "Q 735+832 T 1567 ☒ 1568\n",
      "Q 444+577 T 1021 ☑ 1021\n",
      "Q 397+68  T 465  ☑ 465 \n",
      "Q 502+573 T 1075 ☒ 1065\n",
      "Q 379+29  T 408  ☒ 498 \n",
      "Q 14+761  T 775  ☑ 775 \n",
      "Q 70+592  T 662  ☑ 662 \n",
      "Q 7+846   T 853  ☑ 853 \n",
      "Q 45+405  T 450  ☑ 450 \n",
      "\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 32s 703us/step - loss: 0.2879 - accuracy: 0.9411 - val_loss: 0.2246 - val_accuracy: 0.9545\n",
      "Q 20+49   T 69   ☒ 68  \n",
      "Q 8+409   T 417  ☑ 417 \n",
      "Q 69+235  T 304  ☒ 204 \n",
      "Q 38+75   T 113  ☑ 113 \n",
      "Q 759+38  T 797  ☑ 797 \n",
      "Q 762+23  T 785  ☑ 785 \n",
      "Q 97+44   T 141  ☑ 141 \n",
      "Q 535+73  T 608  ☑ 608 \n",
      "Q 996+137 T 1133 ☑ 1133\n",
      "Q 894+557 T 1451 ☑ 1451\n",
      "\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 32s 709us/step - loss: 0.1849 - accuracy: 0.9648 - val_loss: 0.1424 - val_accuracy: 0.9734\n",
      "Q 17+209  T 226  ☑ 226 \n",
      "Q 182+31  T 213  ☑ 213 \n",
      "Q 886+57  T 943  ☑ 943 \n",
      "Q 736+17  T 753  ☑ 753 \n",
      "Q 361+67  T 428  ☑ 428 \n",
      "Q 12+215  T 227  ☑ 227 \n",
      "Q 98+590  T 688  ☑ 688 \n",
      "Q 560+95  T 655  ☑ 655 \n",
      "Q 471+67  T 538  ☑ 538 \n",
      "Q 532+143 T 675  ☑ 675 \n",
      "\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 33s 734us/step - loss: 0.1251 - accuracy: 0.9751 - val_loss: 0.1978 - val_accuracy: 0.9373\n",
      "Q 37+331  T 368  ☑ 368 \n",
      "Q 271+18  T 289  ☑ 289 \n",
      "Q 14+811  T 825  ☑ 825 \n",
      "Q 689+4   T 693  ☒ 793 \n",
      "Q 452+33  T 485  ☑ 485 \n",
      "Q 853+315 T 1168 ☑ 1168\n",
      "Q 22+33   T 55   ☑ 55  \n",
      "Q 197+34  T 231  ☑ 231 \n",
      "Q 825+54  T 879  ☒ 889 \n",
      "Q 229+640 T 869  ☒ 969 \n",
      "\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 32s 710us/step - loss: 0.0926 - accuracy: 0.9805 - val_loss: 0.0710 - val_accuracy: 0.9853\n",
      "Q 42+754  T 796  ☑ 796 \n",
      "Q 332+829 T 1161 ☑ 1161\n",
      "Q 664+3   T 667  ☑ 667 \n",
      "Q 365+53  T 418  ☑ 418 \n",
      "Q 9+663   T 672  ☑ 672 \n",
      "Q 991+938 T 1929 ☑ 1929\n",
      "Q 511+318 T 829  ☑ 829 \n",
      "Q 14+440  T 454  ☑ 454 \n",
      "Q 9+639   T 648  ☒ 658 \n",
      "Q 639+743 T 1382 ☑ 1382\n",
      "\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 33s 732us/step - loss: 0.0748 - accuracy: 0.9832 - val_loss: 0.0745 - val_accuracy: 0.9811\n",
      "Q 70+747  T 817  ☑ 817 \n",
      "Q 60+768  T 828  ☑ 828 \n",
      "Q 245+72  T 317  ☑ 317 \n",
      "Q 389+209 T 598  ☒ 698 \n",
      "Q 68+999  T 1067 ☑ 1067\n",
      "Q 909+3   T 912  ☑ 912 \n",
      "Q 894+560 T 1454 ☑ 1454\n",
      "Q 87+416  T 503  ☑ 503 \n",
      "Q 565+968 T 1533 ☒ 1543\n",
      "Q 721+49  T 770  ☑ 770 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print()\n",
    "    print(\"Iteration\", epoch)\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(\"☑ \" + guess)\n",
    "        else:\n",
    "            print(\"☒ \" + guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy with the LSTM encoder and deductron decoder is comparable to using LSTM in both roles. This adds credibility to the idea that the problem in the previous test was insufficient feature extraction by the deductron layer.\n",
    "\n",
    "Reversing the roles of the LSTM and deductron adds more weight to this idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "deductron_4 (Deductron)      (None, 128)               19840     \n",
      "_________________________________________________________________\n",
      "repeat_vector_4 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 152,972\n",
      "Trainable params: 152,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Deductron encoder, LSTM decoder\n",
    "num_layers = 1  # Number of layers in the decoder.\n",
    "model = keras.Sequential()\n",
    "model.add(deductron.Deductron(128, activation = clipped_relu, input_shape=(MAXLEN, len(chars))))\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "\n",
    "model.add(layers.LSTM(128, return_sequences=True))\n",
    "\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 38s 845us/step - loss: 1.7698 - accuracy: 0.3565 - val_loss: 1.6711 - val_accuracy: 0.3809\n",
      "Q 674+9   T 683  ☒ 161 \n",
      "Q 842+361 T 1203 ☒ 101 \n",
      "Q 3+665   T 668  ☒ 611 \n",
      "Q 461+7   T 468  ☒ 111 \n",
      "Q 756+80  T 836  ☒ 655 \n",
      "Q 28+219  T 247  ☒ 211 \n",
      "Q 657+47  T 704  ☒ 601 \n",
      "Q 42+73   T 115  ☒ 446 \n",
      "Q 88+114  T 202  ☒ 906 \n",
      "Q 704+521 T 1225 ☒ 101 \n",
      "\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 33s 738us/step - loss: 1.6271 - accuracy: 0.4014 - val_loss: 1.5986 - val_accuracy: 0.4085\n",
      "Q 932+18  T 950  ☒ 301 \n",
      "Q 61+190  T 251  ☒ 101 \n",
      "Q 175+8   T 183  ☒ 12  \n",
      "Q 87+669  T 756  ☒ 855 \n",
      "Q 762+23  T 785  ☒ 394 \n",
      "Q 499+161 T 660  ☒ 104 \n",
      "Q 646+8   T 654  ☒ 141 \n",
      "Q 435+73  T 508  ☒ 411 \n",
      "Q 3+273   T 276  ☒ 340 \n",
      "Q 965+85  T 1050 ☒ 104 \n",
      "\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 34s 764us/step - loss: 1.5392 - accuracy: 0.4284 - val_loss: 1.5041 - val_accuracy: 0.4424\n",
      "Q 31+142  T 173  ☒ 155 \n",
      "Q 169+442 T 611  ☒ 713 \n",
      "Q 53+254  T 307  ☒ 587 \n",
      "Q 346+242 T 588  ☒ 787 \n",
      "Q 746+56  T 802  ☒ 711 \n",
      "Q 108+303 T 411  ☒ 413 \n",
      "Q 121+247 T 368  ☒ 493 \n",
      "Q 68+47   T 115  ☒ 151 \n",
      "Q 772+82  T 854  ☒ 800 \n",
      "Q 230+3   T 233  ☒ 33  \n",
      "\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 37s 820us/step - loss: 1.4433 - accuracy: 0.4619 - val_loss: 1.4130 - val_accuracy: 0.4744\n",
      "Q 402+773 T 1175 ☒ 117 \n",
      "Q 953+98  T 1051 ☒ 104 \n",
      "Q 0+316   T 316  ☒ 31  \n",
      "Q 354+68  T 422  ☒ 411 \n",
      "Q 410+16  T 426  ☒ 111 \n",
      "Q 371+4   T 375  ☒ 47  \n",
      "Q 416+76  T 492  ☒ 487 \n",
      "Q 578+995 T 1573 ☒ 1444\n",
      "Q 519+350 T 869  ☒ 609 \n",
      "Q 423+846 T 1269 ☒ 110 \n",
      "\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 33s 734us/step - loss: 1.3568 - accuracy: 0.4921 - val_loss: 1.3463 - val_accuracy: 0.4964\n",
      "Q 350+254 T 604  ☒ 775 \n",
      "Q 6+138   T 144  ☒ 175 \n",
      "Q 966+88  T 1054 ☒ 105 \n",
      "Q 29+410  T 439  ☒ 299 \n",
      "Q 13+800  T 813  ☒ 811 \n",
      "Q 85+480  T 565  ☒ 838 \n",
      "Q 757+873 T 1630 ☒ 1511\n",
      "Q 939+783 T 1722 ☒ 1211\n",
      "Q 986+1   T 987  ☒ 177 \n",
      "Q 774+793 T 1567 ☒ 1611\n",
      "\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 33s 729us/step - loss: 1.2891 - accuracy: 0.5164 - val_loss: 1.2917 - val_accuracy: 0.5174\n",
      "Q 922+87  T 1009 ☒ 909 \n",
      "Q 303+987 T 1290 ☒ 1109\n",
      "Q 866+282 T 1148 ☑ 1148\n",
      "Q 974+46  T 1020 ☒ 1009\n",
      "Q 51+946  T 997  ☒ 906 \n",
      "Q 675+80  T 755  ☒ 836 \n",
      "Q 77+500  T 577  ☒ 777 \n",
      "Q 934+593 T 1527 ☒ 1448\n",
      "Q 80+278  T 358  ☒ 398 \n",
      "Q 297+268 T 565  ☒ 105 \n",
      "\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 32s 704us/step - loss: 1.2250 - accuracy: 0.5412 - val_loss: 1.2244 - val_accuracy: 0.5409\n",
      "Q 22+471  T 493  ☒ 453 \n",
      "Q 25+79   T 104  ☒ 191 \n",
      "Q 448+730 T 1178 ☒ 124 \n",
      "Q 419+186 T 605  ☒ 557 \n",
      "Q 509+351 T 860  ☒ 641 \n",
      "Q 414+6   T 420  ☒ 445 \n",
      "Q 508+76  T 584  ☒ 687 \n",
      "Q 99+749  T 848  ☒ 103 \n",
      "Q 6+463   T 469  ☒ 649 \n",
      "Q 764+7   T 771  ☒ 781 \n",
      "\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 33s 727us/step - loss: 1.1577 - accuracy: 0.5648 - val_loss: 1.1654 - val_accuracy: 0.5615\n",
      "Q 862+62  T 924  ☒ 824 \n",
      "Q 158+760 T 918  ☒ 722 \n",
      "Q 313+23  T 336  ☒ 344 \n",
      "Q 334+941 T 1275 ☒ 1385\n",
      "Q 629+565 T 1194 ☒ 121 \n",
      "Q 365+18  T 383  ☒ 324 \n",
      "Q 284+400 T 684  ☒ 804 \n",
      "Q 586+49  T 635  ☒ 644 \n",
      "Q 327+140 T 467  ☒ 577 \n",
      "Q 995+847 T 1842 ☒ 1991\n",
      "\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 36s 796us/step - loss: 1.1020 - accuracy: 0.5850 - val_loss: 1.1124 - val_accuracy: 0.5852\n",
      "Q 790+706 T 1496 ☒ 1407\n",
      "Q 919+211 T 1130 ☒ 1122\n",
      "Q 796+2   T 798  ☒ 169 \n",
      "Q 509+93  T 602  ☒ 699 \n",
      "Q 91+983  T 1074 ☒ 1010\n",
      "Q 976+22  T 998  ☒ 999 \n",
      "Q 952+510 T 1462 ☒ 1461\n",
      "Q 639+73  T 712  ☒ 702 \n",
      "Q 96+237  T 333  ☒ 323 \n",
      "Q 456+662 T 1118 ☒ 1101\n",
      "\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 31s 686us/step - loss: 1.0501 - accuracy: 0.6040 - val_loss: 1.1008 - val_accuracy: 0.5849\n",
      "Q 868+99  T 967  ☒ 987 \n",
      "Q 12+60   T 72   ☒ 62  \n",
      "Q 898+0   T 898  ☑ 898 \n",
      "Q 323+47  T 370  ☒ 317 \n",
      "Q 405+451 T 856  ☒ 995 \n",
      "Q 9+663   T 672  ☒ 692 \n",
      "Q 22+614  T 636  ☒ 663 \n",
      "Q 24+456  T 480  ☒ 419 \n",
      "Q 8+746   T 754  ☒ 681 \n",
      "Q 370+32  T 402  ☒ 303 \n",
      "\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 33s 743us/step - loss: 1.0046 - accuracy: 0.6202 - val_loss: 1.0434 - val_accuracy: 0.6059\n",
      "Q 40+329  T 369  ☒ 339 \n",
      "Q 780+19  T 799  ☒ 899 \n",
      "Q 567+14  T 581  ☒ 582 \n",
      "Q 8+65    T 73   ☒ 64  \n",
      "Q 29+269  T 298  ☒ 328 \n",
      "Q 325+287 T 612  ☒ 909 \n",
      "Q 578+995 T 1573 ☒ 1554\n",
      "Q 605+861 T 1466 ☑ 1466\n",
      "Q 54+423  T 477  ☒ 487 \n",
      "Q 148+9   T 157  ☑ 157 \n",
      "\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 33s 731us/step - loss: 0.9670 - accuracy: 0.6333 - val_loss: 0.9989 - val_accuracy: 0.6187\n",
      "Q 402+773 T 1175 ☒ 1204\n",
      "Q 321+973 T 1294 ☒ 1204\n",
      "Q 574+96  T 670  ☒ 741 \n",
      "Q 9+639   T 648  ☑ 648 \n",
      "Q 713+98  T 811  ☑ 811 \n",
      "Q 471+829 T 1300 ☑ 1300\n",
      "Q 11+691  T 702  ☑ 702 \n",
      "Q 146+66  T 212  ☒ 202 \n",
      "Q 947+81  T 1028 ☒ 1055\n",
      "Q 5+517   T 522  ☒ 52  \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print()\n",
    "    print(\"Iteration\", epoch)\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(\"☑ \" + guess)\n",
    "        else:\n",
    "            print(\"☒ \" + guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network has only marginally better performance than the pure deductron, suggesting that the low performance was tied specifically to the deductron in the encoder role, not the absence of an LSTM layer in the pure deductron network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "The above tests show that the deductron architecture is capable of learning the sequence-to-sequence addition task. However, in the encoder-decoder network structure, the deductron does not perform as well as LSTM in the \"encoder\" role. Using LSTM for the encoder and deductron for the decoder reaches approximate parity with the LSTM-LSTM network; reversing the roles leads to slower learning. This suggests that the deductron may not have enough complexity to extract the necessary features for this task, but is effective at using these features once learned by the LSTM layer."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
